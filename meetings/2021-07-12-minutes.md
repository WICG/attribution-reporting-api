# Attribution Reporting API

July 12, 2021

Meet link: [https://meet.google.com/jnn-rhxv-nsy](https://meet.google.com/jnn-rhxv-nsy)

Previous meetings: [https://github.com/WICG/conversion-measurement-api/tree/main/meetings](https://github.com/WICG/conversion-measurement-api/tree/main/meetings)

Use Google meet “Raise hand” for queuing


# Agenda



* Introductions
* Scribe volunteer (someone other than Erik/Maud this time)
    * Erik Anderson
* FYI: I2P on attribution reporting with aggregate reports ([link](https://groups.google.com/a/chromium.org/g/blink-dev/c/2zA5-TuVSkA))
    * Charlie: Intent to Prototype on Blink-dev last week on Attribution Reporting API w/ Aggregate Reports. Explainer we published a few weeks back and had discussed in previous calls. Some implementation is starting on the Chrome side-- stay tuned and hopefully prototypes will be out there soon. Further updates will be made to this group.
    * Erik Taubeneck: “soon?” Weeks? Months? Years?
    * Charlie: probably closer to months-- just the way the Chrome schedule works even if we land code now it will take months to reach stable. I will loop back when we have firmer timelines. Implementation has randomizing aspects-- ephemeral worklet that gets sensitive information and a dedicated execution environment to execute that code is pretty gnarly for security reviews since it’s exploring a new security boundary in the browser. Depending on where we land on that with security reviews it could be pretty simple to implement or difficult to implement in a performant way.
    * Erik T: that needs to be solved for the prototype and not just for when 3p cookies go away? More of a threat than 3p cookies?
    * Charlie: Potentially. Normal site isolation compromise, e.g. sites that are not even colluding may have sites or credentials leaked to malicious sites. It turns out that threat ends up being the motivating factor for most of the complexity; not much we can do to say we’re strictly better than 3p cookies if we introduce it. \
 \
We’re thinking of some ways to reduce the need for this worklet dependency. Don’t have a concrete proposal yet, but might file an issue for a declarative process for creating aggregation keys. The worklet we designed right now is maximally expressive and flexible and you can do all sorts of ways to create keys (e.g. hierarchical, just hash strings). It’s possible something simpler that is declarative that looks like the existing API could work. If anyone has any great ideas there that would be good and we want to put on the roadmap as another alternative for people who don’t need all of the sophistication of a worklet or don’t want to run script at all on the advertiser’s page.
* Header-based registration
    * [https://github.com/WICG/conversion-measurement-api/issues/91](https://github.com/WICG/conversion-measurement-api/issues/91)
    * Thoughts on having something like this for source registration?
    * John Delaney: the issue talks about how conversions get registered. We do the same sort of thing that PCM does-- if you want to register a conversion, do a same-origin redirect to a certain URL so that the origin doing that “consents” to doing a conversion. Another way that is more straightforward is to just return a response header-- they’re in control there as well and you get the same sort of consent. You can package all of the attribution parameters into a structured header instead of a long query string and don’t need a well-known URL. Might give you better control, e.g. if you have an open redirector bug someone might register conversions for you whereas headers aren’t susceptible to that sort of bug. \
 \
Also looking at if the same should apply on the source declaration side. You have to set a bag of options on an anchor tag. Worth exploring if we could do something similar where you respond with a response header that creates an impression. This would align the controls on who can register an impression. Qs: how does this work for clicks? On navigation redirects? You’re essentially telling people “if you want to use this API you should put redirects on your navs” which isn’t ideal for perf, but that’s the status quo today so maybe not crazy.
    * Charlie: redirecting through reporting origin so it can return a response header to configure the navigational source? Would be nice if we could avoid something like that.
    * John: if you just have an img tag and you want to register a view impression, but you could do with a header-based mechanism. A lot more thinking to do and write down-- maybe have a separate issue for source declaration and gotchas. If you have feedback on if this would be desirable instead of the current system with multiple attributes or at network request time instead of page load or click time, is that beneficial?
    * Erik T: if you did it in the header, would every impression on the page have the same attributes?
    * John: I don’t think so, this is subresources returning the header. Two different img tags to two different reporting origins can register their own with their own attributes.
    * Charlie: one thing that’s come up here w/ header-based impressions is that the permissions model for who can register changes. Current API-- register if you have access to JS on the 1p context or are in control of the markup you deliver to the browser; it’s a pretty highly trusted environment, only things publisher puts directly into the page. If they put JS into the page they’re putting a lot of trust into the JS to do what it says. If we move it to something configured on network requests, the permissions model potentially changes to “by embedding any 3p resource on the page, I delegate the responsibility for registering impressions to those 3p resources.” Might be too permissive, might not expect random fonts or images to be configuring the attribution reporting API on your site. It would be good to get feedback in that dimension as well and any ideas people have for ways to mitigate this, e.g. permissions policy or other things publishers can configure (opt in or opt out).
    * John: It’s worth noting the conversion side is there today. Each of the mechanisms doesn’t currently align. Maybe the conversion side should be less permissive-- as it is it’s less balanced.
    * Charlie: yes, that’s correct that it’s less balanced. Only permissions policy we have on the API is for publishers and advertisers to turn it off completely or in subframes. Just an on/off switch permissions policy.
    * Erk T: if we can stay as close to PCM as possible, it becomes easier to merge down the road. Doesn’t work on impression side and it gives them a different paradigm to think about. They’re using link decoration on the conversion side, is that right?
    * Charlie: if an HTTP response is a redirect to a certain well-known URL with some parameters in the URL. That’s also our current design and is pretty aligned. The problem is that it’s a bit of an odd API from the web’s point of view-- you don’t normally configure network requests using this sort of approach, so I think it would be a little bit more web platform compliant to do something with response headers. Overall, with security issues and permissions issues they’re the same with response headers. Two separable things-- can we move the conversion registration to use response headers and I feel like we could bring that to the Privacy CG.
    * Erik T: we should sort it out here, but would be good to contribute that there.
    * Charlie: John is spec’ing this stuff now and not a lot of spec hooks yet for parsing a URL and taking parameters out of it.
    * John: next steps are to file an issue and propose the exact mechanism.
    * Charlie: you can propose the mechanism on issue 91 for the conversion side and it might be worthwhile to tag some of the PCM folks like John Wilander before we put it on the agenda over there to get their take on it.
* Budget management
    * [https://github.com/WICG/conversion-measurement-api/issues/176](https://github.com/WICG/conversion-measurement-api/issues/176)
    * Charlie: We had talked about this a little bit last week. In the aggregate explainer, there’s this notion of a “sensitivity budget” which limits the total amount of histogram contributions that a client can send, partitioned in particular dimensions: cross advertiser cross site cross time. Internal feedback was that this is hard to manage; in order to maximally utilize the API you have to have a predictive guess on how much the user is going to contribute and then tune how much budget you’ll consume accordingly. \
 \
Two ways this can cause problems: (1) if you don’t use enough of the budget, you’re paying for it with more relative error; (2) if you consume too much budget, the problem is that subsequent conversions and reports will be dropped and there will be a bias in the outcome… you’re maximally using the budget but are dropping the reports in some biased way such as prioritizing earlier conversions. \
 \
Both of those things are pretty bad. One small mitigation would be to allow you to see the budget as you consume it. In the worklet design, we can pass the budget remaining so you can see how much you have left and can make decisions based on that. Stop making contributions based on that if there’s some buckets you only have on a best-effort basis and prioritize your P0 aggregates. \
 \
Another technique we’re thinking about is shrinking the time windows. This budgeting issue compounds when you have to make these decisions over a long time. If you had a 30 day window in which you had to use a 1000 histogram contributions, predicting how many conversions or interactions a user will have is much much harder than predicting how many they’ll have in a day period (something like that). Shrinking the windows also minimizes the impact of mistakes. If you consume all of your budget in one go, if it doesn’t reset for 30 days you’re in trouble for the whole 30 days, but with a day you might only lose a half day’s data. There’s cons with this approach too-- divvy up the budget in this daily way but make sure the privacy loss doesn’t accumulate too much over longer time spans. Doesn’t have to be a 1:1 thing, if you have a budget over X days, might be able to do more than X/30 days on the basis that attacks that use all of the budget would require the user to go back to those two sites every day. No formal analysis yet, but one solution that might make this budgeting less of a big deal. \

    * Basile Leparmentier: On the budget, it’s not only what you said, but also the number of dimensions we might ask about. Publisher/advertiser/size, might be able to maximize. If we also want the type of display, divide by two. If we also want another thing, divide by 3. The other issue is we might want higher precision… it’s an issue where if we want to play with a number we might be over/under but we also have a subdimension of how many dimensions we’re asking about. It’s quite tough to know how we’ll be able to optimize it. Not to say I have a good answer to it…
    * Charlie: That makes sense. We’re going to run into that no matter what based on the nature of the differential privacy aims we’re trying to achieve. One thing that is particularly difficult for us to achieve with a budget consumed over time with dimensions is what if you change your mind part way into the window? You want to ditch a couple of dimensions-- how do you interpret the results if you do that; seems challenging to do that. The fact that this data is coming back in multiple dimensions makes this more critical.
    * Erik T: this makes different difficulties. If you move the entire budgeting into the aggregate service. You should have a really good idea of how many reports you want to query over time, then allocate your budget based on the number of reports. Implementing budgeting in the aggregate service will be complicated if dealing with the cross section, but I don’t think it’s impossible.
    * Charlie: that’s an approach we can consider. Two difficulties here that make me pause: (1) if you want user-level protections, I feel that to get that, you need to send user IDs to the helper or at least some IDs that link the user together which is further info the helpers have which could be sensitive. Could learn new things about a user’s behavior. (2) Complexity if we want to integrate such a system into a MPC protocol seems really gnarly. Did you have that in mind when you proposed this?
    * Erik T: they’ll be doing some privacy management already, this just increases the scope of that. Nothing stands out to me as that much harder. You’re right there’s more IDs that need to be passed along and managed. Maybe missing something, but at first glance it doesn’t seem extraordinarily more complicated than the management they’re already tasked with.
    * Charlie: the question is, “Are these things that need to be hidden from the helpers or can they be shared directly?” Right now, we’re trying to hide everything from the helpers that we hide from the ad tech. The budgeting is stuff that an ad tech can also track. We have a number of things we’re willing to give away in the clear so an advertiser can track privacy budget. We could also send an ID to the advertisers and helpers which could be a pseudonymous identifier, but I worry it will be one step too far and reveal too much about the user’s behavior. One user could contribute a thousand records and it could identify their behavior. If you try to hide it, then you’d want to hide from both the ad tech and aggregator to solve the collusion problem. It’s possible we could come up with something clever.
    * Erik T: I see the problem now, that’s helpful. I have some thoughts.
    * Charlie: this issue is a good spot to discuss further.
    * Brian May: is it correct to see this as ad tech participants deciding to hold on and provide the most intelligence they can for a given user or waiting longer to get a comprehensive view?
    * Charlie: yes, 90% of it. There’s a fixed budget, once you use up all of that budget for reports, you can’t make more contributions to the aggregate histogram. At a particular event, you have to decide how much budget it’s worth to you. Prioritize it over future, unknown events or prioritize lower because I predict more valuable stuff is coming up that I want to measure more.
    * Brian: devolves to “most important to me will always be prioritized and I will always conserve my budget for those.” If I didn’t use all of my budget, can I use it up at the end?
    * Charlie: maybe get a notification and you get an opportunity to log some extra things. Unknown how that would work, but please log them in the issue. We don’t have any concrete ideas that keep the API simple. Maybe we could have a pending, speculative report and prioritize them but I would like to avoid adding a ton of extra complexity in the API there. Worth noting that that introduces multiple new complexities-- you may be incentivized to hold off until you know all of the events the user did in the time period and this would introduce delays. We heard delays aren’t great, so we created the aggregate report. If you want to know everything, you’d need to add delays on your end.
    * Brian: some things would be “report now” and somethings would be “this can wait” and maybe some signal that things are about to reset.
    * Charlie: if you scope it to non-essential things, the approach makes more sense. If you use all of your budget and they get dropped, maybe you don’t care too much.
    * Brian: this might change how everyone thinks about how things work.
    * Charlie: not logging extraneous activity is a good thing in our book.
    * Mehul: to add to what Erik T was talking about, if there are helpers and DP noise being added, what is the budget trying to achieve further? Why can’t DP be enhanced further so it doesn’t require budgeting? That would be a no-state situation even without a pseudonymous identifier.
    * Charlie: what is the budget for?: if we think of a histogram composed of all of the user’s contributions for a given publisher+advertiser+time window, the budgets are a bound on the sensitivity of that histogram. What we want to say is, “what is the maximum amount a user could contribute to the histogram?” In the current design, that’s hardcoded; the client determines how much a given user can contribute to the histogram. Helpers add a fixed amount of noise every time. They know the user has a max contribution of _s_, so helpers can add a fixed amount of noise to that. Most DP systems need to have some sort of bound on how much a user can contribute; if absolutely no bound, no amount of noise can hide that one user’s contribution.
    * Mehul: if DP noise scales with the data being queries again and again. You stamp the data records and if the next time the data is asked, the noise goes up, if you ask again, the noise goes up again.
    * Charlie: imagine the situation where you have a batch of encrypted records. 1M total, 500K from one user. The user contributes most of the value in the histogram. How should the aggregation server know how much noise to add in that case?
    * Mehul: it’s cross-dimensionality, you didn’t give the helper an ID. Other parties won’t know if 500K were from one user or from many users. If you added noise to it, you’ve hidden if that user was present or not.
    * Charlie: you can make the hypothetical even simpler-- I want to track if Mehul converted. If everyone else converts, I add 1 to their histogram budget. If Mehul does, I add 1 million. How much noise will the aggregator need to add so it protects you? They’ll need to add noise proportional to a million, but that somehow has to be known in advance.
    * Mehul: The helper service could handle it a little differently without a fixed budget. Should discuss more offline.
    * Charlie: I agree we could do this not on the client, but it needs to be done by someone to some extent. You need to have some way of ensuring the final aggregate computation has a bounded sensitivity. The helpers can do that-- totally agree-- but my point is it needs to be done in some way.
    * Brian: There’s a similar problem on the client in terms of how much you can store there. At some point you need to prioritize the events you’re storing because you’ll run out of space.
    * Charlie: that’s true, but my guess is that in most of the cases, the privacy constraints will be more pressing than resource use constraints like disk. Lots of caveats to that statement. That’s a fair point, there will be some resource constraints on the APIs just to make sure the user’s disk doesn’t get filled up with events. Not expecting that to be a big issue. We should have the limits that Chrome sets be documented and bring it up in a meeting to make sure it doesn’t seem too crazy to people.
    * Brian: same problem being solved for two different reasons.
    * Charlie: depends on how big of a problem disk usage is. Theoretically it’s the same constraints, but if the loss is negligible it may not add any complexity on ad tech systems. \

* Qs about aggregate APIs [https://github.com/WICG/conversion-measurement-api/issues/154](https://github.com/WICG/conversion-measurement-api/issues/154) 
    * Basile: discussed this a little bit ago. I had asked how you expected to make this work and there’s an answer now that’s a little clearer. It’s about how you use weights to make the contribution. My understanding is that I could put a vector of 2^44 (?) as a dictionary. bit 1 is video, bit 2 is not video, bit 3 is display size, and so on. A big, big key. Add a single key for a cross feature. Another way of understanding is that you could use it in a more hierarchical way-- the first bit could say it’s a video, 2nd bit could be the size of the display, 3rd bit could be publisher domain and if you want data on the 3rd bit, you’d have the cross of the video, size, and domain. Which means the 3rd one has a lot of noise. If you want data on only one publisher domain you’ll have a lot of noise. \
 \
I want to make sure we can do something like the first one rather than the second one-- I could say Id 10,536 is equal to display size 25-- maybe it’s a cross, triple cross, whatever I want; is this correct? I want to clarify that most of our data at Criteo is not hierarchical. The display size is info itself-- not just on one publisher but want across all domains. Might also want cross features. Most of the time is the non-hierarchical thing. Knowing that, at least for Criteo, for a single sale we will want to put publisher in a lot of places. Small contribution on a publisher, then another small display size on another publisher. To explain to myself, it’s how I would use this API. This means that we will query a lot of dimensions all the time for each attribution. This has two issues-- a lot of what I will query will be 0 and have a lot of noise. If we want to use this for optimization, a similar thing will have to be used. We will have to target a lot of prefixes and we will ask for a lot of dimensions and the noise will be quite huge.
    * Charlie: the feedback is good, what you described makes sense. It’s a use case we hope to support with the query model in the API. The stuff with prefixes and hierarchies is an optimization for a specific type of data. If you have hierarchical data, this protocol does a good job on computational overhead. If your data is scattered around and structured… non-hierarchical keys are totally supported and fine.
    * Basile: for you and MPC, it may be an issue. It’s not the same thing when you query only the prefixes. For instance, we might want non-sparse 2^44 keys. Be aware that Criteo and I would be surprised if others don’t do something similar. Optimization on sparsity may be quite important.
    * Charlie: if you can share any data there, even if it’s just what you described in a written down issue, so that we can think through algorithms we’re thinking about for MPC. If you’re trying to query a full 2^33 keys that will be expensive with or without MPC.
    * John: The aggregate explainer currently has a limit on the number of contributions that can be returned from the worklet; seems to impact this use case of a single contribution affecting a lot of hierarchies. That limit might make it so you can only contribute to “is video”, “ad size”, and one other feature. Not an exact limit in the explainer yet.
    * Charlie: we should edit the explainer with a larger example to make it clear these use cases are supported.
    * Mehul: The same record contributing to multiple aggregations is the same as the previous budget discussion. Might not be a straightforward count/limit. \
 \
Adding to Basile’s thing, the explainer currently has too much complexity to accommodate DPF. Would be helpful to see if it can be simplified. Most conversions key/value pair. Advertiser could have 15 campaigns, then create a 16th campaign and need an additional bit.
    * Charlie: that’s a great point, keeping track of these buckets seems really difficult-- we’re brainstorming. We spent a while exploring techniques that would allow hashes but ran into a bunch of roadblocks there. Key complexity coming from MPC requirements. We made MPC optional for the current explainer so you can get key/value pairs in the clear and implement simpler things. We would be open to expanding the key size/space. The current example is something like 2^32, but could go higher. We’re aware of ergonomics issues here and are trying to explore the best way to solve this with MPC and this is the best we’ve found so far.
    * Mehul: we’ve been working with Microsoft Research folks to explore that further.
    * Charlie: sure, feel free to use github to organize a conversation on that.
* Any other business
    * See Masked LARK proposal from Microsoft: [https://github.com/WICG/conversion-measurement-api/issues/181](https://github.com/WICG/conversion-measurement-api/issues/181), https://github.com/WICG/privacy-preserving-ads/blob/main/MaskedLARK.md


# Attendees — please sign yourself in! 



1. 
2. Charlie Harrison (Google Chrome)
3. Brian May (dstillery)
4. 
5. 
6. Brendan Riordan-Butterworth (IAB Tech Lab / eyeo GmbH)
7. Jonasz Pamuła (RTB House)
8. Erik Taubeneck (Facebook)
9. Andrew Pascoe (NextRoll)
10. Alois Bissuel (Criteo)
11. Marshall Vale (Google Chrome)
12. Bill Landers (Xandr)
13. Maud Nalpas (Google Chrome)
14. Erik Anderson (Microsoft)
15. Valentino Volonghi (NextRoll)
16. Julien delhommeau (Xandr)
17. Paul Marcilhacy (Criteo)
18. Przemyslaw Iwanczak (RTB House)
19. Larissa Licha (NextRoll)
20. Basile Leparmentier (Criteo)
21. Matt Zambelli (Neustar)
22. Aditya Desai (Google)
