# Attribution Reporting API

Mon Nov 18th, 2024 @ 9am PT

This doc: bit.ly/ara-meeting-notes

Meet link: [https://meet.google.com/jnn-rhxv-nsy](https://meet.google.com/jnn-rhxv-nsy)

Previous meetings: [https://github.com/WICG/conversion-measurement-api/tree/main/meetings](https://github.com/WICG/conversion-measurement-api/tree/main/meetings)

Meeting issue: [https://githubhttps://github.com/WICG/conversion-measurement-api/issues/80.com/WICG/conversion-measurement-api/issues/80](https://github.com/WICG/conversion-measurement-api/issues/80)



* Use Google meet “Raise hand” for queuing.
* If you can’t edit the doc during the meeting, try refreshing as permissions may have been updated after you loaded the page.
* If you are not admitted to the meeting, try rejoining. Google Meet has some UI that makes it easy to misclick if someone simultaneously requests to join while someone else is typing into the meeting chat.
* Please make sure to join [W3C](https://www.w3.org/) and [WICG](https://www.w3.org/community/wicg/) if you plan on participating


# Agenda



* Chair: Charlie Harrison
* Scribe volunteer: Arpana Hosabettu (Google Chrome)

Please suggest agenda topics here! (either in a comment or a suggestion on the doc:



* FYI:[ attribution scopes](https://github.com/WICG/attribution-reporting-api/blob/main/attribution_scopes.md) - released in M130
* FYI:[ named budgets](https://github.com/WICG/attribution-reporting-api/pull/1422)
* FYI:[ change to ar_debug requirement](https://github.com/WICG/attribution-reporting-api/pull/1441)
* Understand flexible event-level usage and if there is feedback/interest in[ (1) multiple trigger specs and (2) summary buckets](https://github.com/WICG/attribution-reporting-api/blob/main/flexible_event_config.md#ideas-for-future-iteration)
* [Github Issue #1442:](https://github.com/WICG/attribution-reporting-api/issues/1442) Additional event-level configurations
* [Github Issue #1437](https://github.com/WICG/attribution-reporting-api/issues/1437): batched source registration
* [Github Issue #71](https://github.com/privacysandbox/aggregation-service/issues/71): aggregation service requerying
* 


# Attendees — please sign yourself in! 

(Please sign in at the start of the meeting)



1. Andrew Paseltiner (Google Chrome)
2. David Dabbs (Epsilon)
3. Matt Lamont (Cadent)
4. Charlie Harrison (Google Chrome)
5. Aloïs Bissuel (Criteo)
6. Akash Nadan (Google Chrome)
7. Hannah Chang (Google Chrome)
8. Nan Lin (Google Chrome)
9. Stacy Andrade (Cadent)
10. Michal Kalisz (RTB House)
11. Rushil Walia (Google Chrome)
12. Arpana Hosabettu (Google Chrome)


# Notes



* Announcements 
    * FYI:[ attribution scopes](https://github.com/WICG/attribution-reporting-api/blob/main/attribution_scopes.md) - released in M130 (~Oct 15)
        * Presented earlier in this forum 
        * Fine grained filtering that takes place before rest of attribution process
        * Most useful when you have multiple advertisers or campaigns converting on the same destination sites to make sure the conversion is attributed to the right campaign or advertiser.
        * (David Dabbs) - Is it at 100% - on Chrome yes 
    * FYI:[ named budgets](https://github.com/WICG/attribution-reporting-api/pull/1422)
        * New feature currently working on - tentatively coming early-mid January.
        * Pre allocation of budgets associated with conversion. Allows to define diff buckets for conv. For example navigation vs views - give max of X amount of budget that falls in the conversion-type. L1 budget allocation will also check for this bucket 
        * (Aloïs Bissuel (Criteo)) Looks interesting will take a deeper look
        * (David Dabs) - Does it only apply to navigation that precedes>
            * Akash - This is different about preallocating budgets for a specific type of conversion
        * Michal Kalisz (RTB House) - Is it only for Agg Reporting or Private Agg Reporting?
            * (Akash Nadan) This most like applies to Private Aggregation as well, but we can find links to those 
            * (Charlie Harrison) Feel free to leave comments and we can look at 
    * FYI:[ change to ar_debug requirement](https://github.com/WICG/attribution-reporting-api/pull/1441) -  part of M132 (~Jan 15)
        * You had to set ar-debug before requesting debug reports. We changed it not requiring ar-debug since chrome will check if there is access to 3P cookies. This should simplify the debug report process. Nan/Charlie - anything to add there? 
        * (Aloïs Bissuel (Criteo)) Has this already been released? 
        * Nan Lin - this will be released 132
    * Understand flexible event-level usage and if there is feedback/interest in[ (1) multiple trigger specs and (2) summary buckets](https://github.com/WICG/attribution-reporting-api/blob/main/flexible_event_config.md#ideas-for-future-iteration)
        * Ability to customize the number of reports and windows for event reports
        * 2 questions for discussions/thoughts 
            * Current usage
            * Couple of ideas for enhancements for trigger specs and summary buckets 
        * Current Usage
            * Any feedback on flex-event or how anyone is using it?
            * Arpana - does the current flex-event seem reasonable and how do people plan to use it?
            * Charlie - named-budget and flex-event is useful when we want to limit low-value events so we should see if it's more valuable on agg or event reports. 
            * (David Dabbs) - Do you all maintain a counter/UMA that indicates the amount of usage of the feature? Is it cos you see the uptake or no usage
            * (Akash Nadan) - Some usage but we want to know if it solves the use cases or if there is anything we should work on
            * (Charlie Harrison) - We don't collect metrics per caller or partner so we cannot really tell if many folks are using or 1 huge partner
        * Enhancements
            * <span style="text-decoration:underline;">Multiple trigger specs</span> : If there are high value conversions you can specify a reporting window, trigger data for those. And different spec for low value conversions to allow more flexibility to capture diff types of conversions. Any initial feedback on that?
            * Aloïs Bissuel (Criteo) -  How does it work in terms of the RR mechanism? If you have 1 type of conversion with lot of metadata and other with low number of metadata
            * (Charlie Harrsion) Underlying thing for noise is the same, calculating the possible outputs but complexity is first figuring out all the states. Spec hand waves this and has a typescript that has the algorithm alongside header validation in the ARA repo
            * Summary Buckets: trade off noise with data granularity. 
            * If you are interested in bucketed count/value this would help with that. 
            * For example: count - instead of receiving conversion counts it would tell 0-10 conversions and the tradeoff is reduced noise. 
            * Charlie - Unlocks the ability to handle more conversion labels in particular aggregatable labels in values. Over the course of the window, it aggregates the value by specifying a bucketing scheme, it says 0-10, 10-50$, 50-100$ buckets and will on buckets. Complexity is specifying the buckets ahead of time and correct use of buckets might be complicated.  In terms of approach, we did have a paper on some discussion on RR on bins for bucketing schemes. If you are using this for Machine learning optimization
                * Link: Regression with Label Differential Privacy [https://arxiv.org/abs/2212.06074](https://arxiv.org/abs/2212.06074)
                * 
        * [Github Issue #1442:](https://github.com/WICG/attribution-reporting-api/issues/1442) Additional event-level configurations
            * Currently with flex you can customize the parameters, there is an info gain limit that limits the configs chosen. If you are interested in choosing the high limit then this option allows you to do that with increased noise 
            * There is a script that tells how much noise there would be if you increase the limit
            * Charlie - Only thing to add is that the amount of noise increase may be unexpectedly large. Biggest concern would be a potentially foot-gun if noise increases by 10X. If you think noise is tolerable for just 2 more outputs. Very scared that it would lead to a surprising amount of noise. 
            * David Dabbs - YNMV (your noise may vary), check the utility for details.
            * Aloïs Bissuel (Criteo)  - What's channel capacity mentioned in issues
            * Analysis of info gains measured in terms of bits. Models the RR as noisy channels, passing one of the domain elements and how many bits that leaks. All the limits are published in the params doc in the spec. [https://github.com/WICG/attribution-reporting-api/blob/main/params/chromium-params.md](https://github.com/WICG/attribution-reporting-api/blob/main/params/chromium-params.md) shows the current values for Chromium
        * [Github Issue #1437](https://github.com/WICG/attribution-reporting-api/issues/1437): batched source registration
            * Potential impacts to adtech servers if there are multiple registrations (coming from 1 page). One potential mitigation would be to have an array of source-registrations
            * Andrew Paseltiner (Google Chrome) - Enables one other thing than just bandwidth enhancements. You can also organize the number of registrations and then optimize on server side like dropping requests that may have overlaps.  
            * Charlie Harrison - How would this feature work ? Would Chrome batch automatically or adtech needs to opt into 
            * Akash Nadan - Initial thinking is that adtech opts into and some logic in adtech side  
            * : One call on server and adtech can respond with multiple responses
            * : We could discuss other options but the minimal feature is returning multiple responses instead of one. 
            * : Ok, so adtech manages the page and optimize bandwidth consumption
            * David Dabbs - Each of those registration request is treated independently, just like PA they can return multiple responses but wont fail the whole batch if there is one failure
            *  - That's right
            * : Even if the publisher has a separate attributionSrc for each source they would still have capability to batch. 10 sources on a page with attrSr but adtech can register 1 response?
            * : Could be independently useful even if they dont do client side optimization. Gives flexibility to choose which one to respond to.
            * David Dabbs: to clarify this refers to publishers but you mean adtech registering those right?
            * : Yes that's right, the issue on github is incorrect
        * [Github Issue #71](https://github.com/privacysandbox/aggregation-service/issues/71): aggregation service requerying
            * Currently, agg Service uses shared-Id for counting; you cannot repeat the same report. This feature will allow the same report to queried multiple times but each batch will need to specify the epsilon to be consumed for that particular query
            * Example: You can have 1 batch with epsilon 32 and then at a later time query the same batch again with epsilon 32. Total epsilon would still be epsilon 64.
            * Curious on initial thought if that's helpful?
            * Aloïs Bissuel (Criteo) -QQ: what happens if on the report if epsilon is too large
            * : We haven't considered fully, but based on feedback 
            * Aloïs Bissuel (Criteo) - What if the batch is rejected will it be able to be queried
            * Charlie Harrison - We can do whatever is right but would appreciate feedback and we can do what is more helpful to adtechs 
            * Aloïs Bissuel (Criteo) - New type of noise distribution or what type of goals you had in mind with requery? Laplace vs 
            * : Not about noise mechanism but privacy notion, even for the same noise mechanism laplace, if you want to requery 100 times under Epsilon delta DP would result in less noise and could potentially introduce Gaussian noise. But right now for the purpose of this issue it's just about requerying the data more time. At Least Private Aggregation we have 1 use case for Reach sketches that motivated this
            * Aloïs Bissuel (Criteo) -Ability to bootstrap in getting confidence-intervals to get few different estimates, will file an issue at some point 
        * End of topic for today, any other question/topic?
            * Michal Kalisz (RTB House) - Wasn't aware of flex event utility. Can you tell little bit more about this tool 
            * : Outline diff config under event level API to noise. Main thing the tool does is takes inputs source event config either in headers of cmd line interface that specifies how many reporting windows there are /pieces of metadata etc and tool computes the same way chrome browser computes the o/p states and flip probability for RR mechanism to satisfy DP for diff epsilon. Tool will also tell info gain and warn if its exceeds the limit. Useful for adtech that want to tune o/p states like need 2 reports and how noise impacts that. Open to feedback. 
            * What fraction has no report or 1 report kind of thing does not exists and want to know if that would be helpful
            * Michal Kalisz (RTB House)  - What about attribution scope? Does it influence the noise. 
            *  - Not sure if that is integrated into this tool?
            * Nan Lin - I think attribution scope is integrated to that tool 
            * Michal Kalisz (RTB House)  - It's really useful
            *  - Header validator can also tell the same information once the request is valid it will tell privacy information
            * David Dabbs - Filtering id can  do count unique - not sure if its an ARA thing but is there more on Reach case.
            *  - Private Aggregation is where we could do Reach msmt right now. [https://github.com/patcg-individual-drafts/private-aggregation-api/blob/main/reach_whitepaper.md](https://github.com/patcg-individual-drafts/private-aggregation-api/blob/main/reach_whitepaper.md) - This outlines how to use filtering-id to do this 
        * Thanks everyone for participating 
